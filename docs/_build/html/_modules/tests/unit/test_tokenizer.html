

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>tests.unit.test_tokenizer &mdash; madmatcher-tools 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            madmatcher-tools
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"></div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">madmatcher-tools</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">tests.unit.test_tokenizer</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for tests.unit.test_tokenizer</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tokenizer</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">AlphaNumericTokenizer</span><span class="p">,</span>
    <span class="n">NumericTokenizer</span><span class="p">,</span>
    <span class="n">WhiteSpaceTokenizer</span><span class="p">,</span>
    <span class="n">ShingleTokenizer</span><span class="p">,</span>
    <span class="n">QGramTokenizer</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tokenizer.vectorizer</span><span class="w"> </span><span class="kn">import</span> <span class="n">TFIDFVectorizer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">PerfectHashFunction</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">feature</span><span class="w"> </span><span class="kn">import</span> <span class="n">DocFreqBuilder</span>

<div class="viewcode-block" id="sample_text">
<a class="viewcode-back" href="../../../source/modules/tests.unit.test_tokenizer.html#tests.unit.test_tokenizer.sample_text">[docs]</a>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sample_text</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create sample text data for testing.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="p">[</span>
            <span class="s1">&#39;Hello World 123&#39;</span><span class="p">,</span>
            <span class="s1">&#39;Python 3.9 Code&#39;</span><span class="p">,</span>
            <span class="s1">&#39;Test Case 456&#39;</span><span class="p">,</span>
            <span class="s1">&#39;Mixed Text 789&#39;</span><span class="p">,</span>
            <span class="s1">&#39;Special Chars @#$&#39;</span><span class="p">,</span>
            <span class="s1">&#39;Numbers 123 456&#39;</span><span class="p">,</span>
            <span class="s1">&#39;Empty String&#39;</span><span class="p">,</span>
            <span class="kc">None</span>
        <span class="p">]</span>
    <span class="p">})</span></div>


<div class="viewcode-block" id="test_alpha_numeric_tokenizer">
<a class="viewcode-back" href="../../../source/modules/tests.unit.test_tokenizer.html#tests.unit.test_tokenizer.test_alpha_numeric_tokenizer">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">test_alpha_numeric_tokenizer</span><span class="p">(</span><span class="n">sample_text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test AlphaNumericTokenizer functionality.&quot;&quot;&quot;</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AlphaNumericTokenizer</span><span class="p">()</span>
    
    <span class="c1"># Test tokenization</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sample_text</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;hello&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">,</span> <span class="s1">&#39;123&#39;</span><span class="p">}</span>
    
    <span class="c1"># Test case insensitivity</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;Hello WORLD&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;hello&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">}</span>
    
    <span class="c1"># Test handling of special characters</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;Hello@World#123&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;hello&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">,</span> <span class="s1">&#39;123&#39;</span><span class="p">}</span>
    
    <span class="c1"># Test empty string</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
    
    <span class="c1"># Test None</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">tokens</span> <span class="ow">is</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="test_numeric_tokenizer">
<a class="viewcode-back" href="../../../source/modules/tests.unit.test_tokenizer.html#tests.unit.test_tokenizer.test_numeric_tokenizer">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">test_numeric_tokenizer</span><span class="p">(</span><span class="n">sample_text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test NumericTokenizer functionality.&quot;&quot;&quot;</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">NumericTokenizer</span><span class="p">()</span>
    
    <span class="c1"># Test tokenization</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sample_text</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;123&#39;</span><span class="p">}</span>
    
    <span class="c1"># Test decimal numbers</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;3.14 42&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;3&#39;</span><span class="p">,</span> <span class="s1">&#39;14&#39;</span><span class="p">,</span> <span class="s1">&#39;42&#39;</span><span class="p">}</span>
    
    <span class="c1"># Test non-numeric text</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;Hello World&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
    
    <span class="c1"># Test mixed content</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;Price: $19.99&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;19&#39;</span><span class="p">,</span> <span class="s1">&#39;99&#39;</span><span class="p">}</span>
    
    <span class="c1"># Test empty string</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
    
    <span class="c1"># Test None</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">tokens</span> <span class="ow">is</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="test_white_space_tokenizer">
<a class="viewcode-back" href="../../../source/modules/tests.unit.test_tokenizer.html#tests.unit.test_tokenizer.test_white_space_tokenizer">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">test_white_space_tokenizer</span><span class="p">(</span><span class="n">sample_text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test WhiteSpaceTokenizer functionality.&quot;&quot;&quot;</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">WhiteSpaceTokenizer</span><span class="p">()</span>
    
    <span class="c1"># Test tokenization</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sample_text</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;hello&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">,</span> <span class="s1">&#39;123&#39;</span><span class="p">}</span>
    
    <span class="c1"># Test multiple spaces</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;Hello   World&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;hello&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">}</span>
    
    <span class="c1"># Test tabs and newlines</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;Hello</span><span class="se">\t</span><span class="s1">World</span><span class="se">\n</span><span class="s1">123&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;hello&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">,</span> <span class="s1">&#39;123&#39;</span><span class="p">}</span>
    
    <span class="c1"># Test empty string</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
    
    <span class="c1"># Test None</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">tokens</span> <span class="ow">is</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="test_shingle_tokenizer">
<a class="viewcode-back" href="../../../source/modules/tests.unit.test_tokenizer.html#tests.unit.test_tokenizer.test_shingle_tokenizer">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">test_shingle_tokenizer</span><span class="p">(</span><span class="n">sample_text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test ShingleTokenizer functionality.&quot;&quot;&quot;</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">ShingleTokenizer</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="c1"># Test tokenization</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;hello world 123&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;helloworld&#39;</span><span class="p">}</span>
    
    <span class="c1"># Test empty string</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
    
    <span class="c1"># Test None input</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">tokens</span> <span class="ow">is</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="test_qgram_tokenizer">
<a class="viewcode-back" href="../../../source/modules/tests.unit.test_tokenizer.html#tests.unit.test_tokenizer.test_qgram_tokenizer">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">test_qgram_tokenizer</span><span class="p">(</span><span class="n">sample_text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test QGramTokenizer functionality.&quot;&quot;&quot;</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">QGramTokenizer</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="c1"># Test tokenization</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sample_text</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;el&#39;</span><span class="p">,</span> <span class="s1">&#39;ll&#39;</span><span class="p">,</span> <span class="s1">&#39;lo&#39;</span><span class="p">,</span> <span class="s1">&#39;o &#39;</span><span class="p">,</span> <span class="s1">&#39; w&#39;</span><span class="p">,</span> <span class="s1">&#39;wo&#39;</span><span class="p">,</span> <span class="s1">&#39;or&#39;</span><span class="p">,</span> <span class="s1">&#39;rl&#39;</span><span class="p">,</span> <span class="s1">&#39;ld&#39;</span><span class="p">,</span> <span class="s1">&#39;d &#39;</span><span class="p">,</span> <span class="s1">&#39; 1&#39;</span><span class="p">,</span> <span class="s1">&#39;12&#39;</span><span class="p">,</span> <span class="s1">&#39;23&#39;</span><span class="p">}</span>
    
    <span class="c1"># Test different q-gram size</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">QGramTokenizer</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;Hello&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="s1">&#39;hel&#39;</span><span class="p">,</span> <span class="s1">&#39;ell&#39;</span><span class="p">,</span> <span class="s1">&#39;llo&#39;</span><span class="p">}</span>
    
    <span class="c1"># Test string shorter than q</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">QGramTokenizer</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;Hi&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
    
    <span class="c1"># Test empty string</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
    
    <span class="c1"># Test None</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">tokens</span> <span class="ow">is</span> <span class="kc">None</span></div>



<div class="viewcode-block" id="test_perfect_hash_function">
<a class="viewcode-back" href="../../../source/modules/tests.unit.test_tokenizer.html#tests.unit.test_tokenizer.test_perfect_hash_function">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">test_perfect_hash_function</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test PerfectHashFunction functionality.&quot;&quot;&quot;</span>
    <span class="c1"># Test hash function creation</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;hello&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">]</span>
    <span class="n">hash_func</span><span class="p">,</span> <span class="n">hash_vals</span> <span class="o">=</span> <span class="n">PerfectHashFunction</span><span class="o">.</span><span class="n">create_for_keys</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>
    
    <span class="c1"># Test hash values</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">hash_vals</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">hash_vals</span><span class="p">))</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>  <span class="c1"># No collisions</span>
    
    <span class="c1"># Test hash function</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">hash_func</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hash_vals</span>
    
    <span class="c1"># Test non-existent key</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">hash_func</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="s1">&#39;nonexistent&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">h</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">hash_vals</span>
    
    <span class="c1"># Test duplicate keys</span>
    <span class="k">with</span> <span class="n">pytest</span><span class="o">.</span><span class="n">raises</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="n">match</span><span class="o">=</span><span class="s1">&#39;keys must be unique&#39;</span><span class="p">):</span>
        <span class="n">PerfectHashFunction</span><span class="o">.</span><span class="n">create_for_keys</span><span class="p">([</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">])</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Dev Ahluwalia.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>