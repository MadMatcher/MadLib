{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43e6cf0",
   "metadata": {},
   "source": [
    "# MadMatcher: Comprehensive Usage Examples\n",
    "\n",
    "This notebook provides a professional, end-to-end demonstration of all public API functions and abstract classes in the MadMatcher toolkit. Each section includes explanations, code examples, and output displays for different input types and configurations.\n",
    "\n",
    "## What is MadMatcher?\n",
    "\n",
    "MadMatcher is a toolkit for entity matching and record linkage that provides:\n",
    "- Multiple tokenization strategies for text preprocessing\n",
    "- Various similarity functions for comparing records\n",
    "- Feature engineering capabilities for machine learning\n",
    "- Active learning support for efficient labeling\n",
    "- Extensible abstract classes for custom implementations\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup](#Setup)\n",
    "2. [Public API Overview](#Public-API-Overview)  \n",
    "3. [Tokenizers and Similarity Functions](#Tokenizers-and-Similarity-Functions)\n",
    "4. [Feature Creation](#Feature-Creation)\n",
    "5. [Featurization](#Featurization)\n",
    "6. [Down Sampling](#Down-Sampling)\n",
    "7. [Seed Creation](#Seed-Creation)\n",
    "8. [Training a Matcher](#Training-a-Matcher)\n",
    "9. [Applying a Matcher](#Applying-a-Matcher)\n",
    "10. [Active Learning Labeling](#Active-Learning-Labeling)\n",
    "11. [Custom Abstract Classes](#Custom-Abstract-Classes)\n",
    "12. [Advanced Examples](#Advanced-Examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ccf19",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install MadMatcher and its dependencies:\n",
    "\n",
    "```bash\n",
    "pip install madmatcher_tools\n",
    "```\n",
    "\n",
    "Import all public API functions and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4587e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from madmatcher_tools import (\n",
    "    # Core functions\n",
    "    get_base_tokenizers, get_extra_tokenizers, get_base_sim_functions,\n",
    "    create_features, featurize, down_sample,\n",
    "    create_seeds, train_matcher, apply_matcher, label_data,\n",
    "    # Abstract base classes for customization\n",
    "    Tokenizer, Vectorizer, Feature, MLModel, Labeler, CustomLabeler\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder.appName('MadMatcherComprehensiveDemo').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab39e59",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Public API Overview\n",
    "\n",
    "MadMatcher exposes the following public API functions and abstract classes:\n",
    "\n",
    "### Core Functions\n",
    "- **`get_base_tokenizers()`**: Returns default tokenizers for text processing\n",
    "- **`get_extra_tokenizers()`**: Returns additional specialized tokenizers  \n",
    "- **`get_base_sim_functions()`**: Returns default similarity functions\n",
    "- **`create_features(A, B, a_cols, b_cols, ...)`**: Generate feature objects for comparing records\n",
    "- **`featurize(features, A, B, candidates, ...)`**: Apply features to candidate pairs\n",
    "- **`down_sample(fvs, percent, search_id_column, ...)`**: Reduce dataset size by sampling\n",
    "- **`create_seeds(fvs, nseeds, labeler, ...)`**: Generate initial labeled examples\n",
    "- **`train_matcher(model_spec, labeled_data, ...)`**: Train a matching model\n",
    "- **`apply_matcher(model, df, feature_col, output_col)`**: Apply trained model for predictions\n",
    "- **`label_data(model_spec, mode, labeler_spec, fvs, ...)`**: Active learning for labeling\n",
    "\n",
    "### Abstract Base Classes (for customization)\n",
    "- **`Tokenizer`**: Base class for text tokenization strategies\n",
    "- **`Vectorizer`**: Base class for converting tokens to vectors  \n",
    "- **`Feature`**: Base class for similarity/distance features\n",
    "- **`MLModel`**: Base class for machine learning models\n",
    "- **`Labeler`**: Base class for labeling strategies\n",
    "- **`CustomLabeler`**: Extended labeler with access to full record data\n",
    "\n",
    "Each section below demonstrates these with different input types and configurations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980c867",
   "metadata": {},
   "source": [
    "## Tokenizers and Similarity Functions\n",
    "\n",
    "MadMatcher provides various tokenizers for text preprocessing and similarity functions for comparing records. Understanding these building blocks is essential for effective feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2158986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available tokenizers and similarity functions\n",
    "base_tokenizers = get_base_tokenizers()\n",
    "extra_tokenizers = get_extra_tokenizers()\n",
    "base_sim_functions = get_base_sim_functions()\n",
    "\n",
    "print('BASE TOKENIZERS:')\n",
    "for i, tokenizer in enumerate(base_tokenizers):\n",
    "    print(f'  {i+1}. {tokenizer.__class__.__name__}: {tokenizer.NAME}')\n",
    "\n",
    "print('EXTRA TOKENIZERS:')\n",
    "for i, tokenizer in enumerate(extra_tokenizers):\n",
    "    print(f'  {i+1}. {tokenizer.__class__.__name__}: {tokenizer.NAME}')\n",
    "\n",
    "print('BASE SIMILARITY FUNCTIONS:')\n",
    "for i, sim_func in enumerate(base_sim_functions):\n",
    "    print(f'  {i+1}. {sim_func.__name__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc16c2fb",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Testing Tokenizers with Different Input Types\n",
    "\n",
    "Let's see how different tokenizers handle various types of input data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f6431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different input types with tokenizers\n",
    "test_inputs = [\n",
    "    'Alice Smith',           # Normal name\n",
    "    'Bob Jones Jr.',         # Name with suffix\n",
    "    'Jean-Pierre O\\'Connor', # Name with special characters\n",
    "    'Company123 Inc.',       # Mixed alphanumeric\n",
    "    '123-456-7890',          # Phone number\n",
    "    '',                      # Empty string\n",
    "    None,                    # None value\n",
    "    42                       # Numeric value\n",
    "]\n",
    "\n",
    "print(\"TOKENIZER TESTING ON DIFFERENT INPUT TYPES\\n\")\n",
    "\n",
    "# Test different tokenizers\n",
    "tokenizers_to_test = [\n",
    "    base_tokenizers[0],  # StrippedWhiteSpaceTokenizer\n",
    "    base_tokenizers[1],  # NumericTokenizer  \n",
    "    base_tokenizers[2],  # QGramTokenizer\n",
    "    extra_tokenizers[0]  # AlphaNumericTokenizer\n",
    "]\n",
    "\n",
    "for tokenizer in tokenizers_to_test:\n",
    "    print(f\"{tokenizer.__class__.__name__} ({tokenizer.NAME}):\")\n",
    "    for input_val in test_inputs:\n",
    "        try:\n",
    "            if input_val is None:\n",
    "                tokens = tokenizer.tokenize(input_val)\n",
    "            else:\n",
    "                tokens = tokenizer.tokenize(str(input_val))\n",
    "            print(f\"  Input: {repr(input_val):<20} â†’ Tokens: {tokens}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Input: {repr(input_val):<20} â†’ Error: {type(e).__name__}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a5c4d",
   "metadata": {},
   "source": [
    "## Feature Creation\n",
    "\n",
    "Feature creation is the core of MadMatcher's functionality. The `create_features()` function automatically generates appropriate features based on your data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create more comprehensive toy DataFrames for testing\n",
    "A = pd.DataFrame({\n",
    "    '_id': [1, 2, 3, 4],\n",
    "    'name': ['Alice Smith', 'Bob Jones', 'Carol Davis', 'David Wilson'],\n",
    "    'age': [25, 30, 28, None],  # Include missing values\n",
    "    'email': ['alice@email.com', 'bob@email.com', None, 'david@email.com'],\n",
    "    'phone': ['123-456-7890', '987-654-3210', '555-123-4567', ''],\n",
    "    'address': ['123 Main St', '456 Oak Ave', '789 Pine Rd', '321 Elm St']\n",
    "})\n",
    "\n",
    "B = pd.DataFrame({\n",
    "    '_id': [101, 102, 103, 104], \n",
    "    'name': ['Alicia Smith', 'Robert Jones', 'Caroline Davis', 'Dave Wilson'],\n",
    "    'age': [26, 29, 28, 35],\n",
    "    'email': ['alicia@email.com', 'robert@gmail.com', 'carol@email.com', None],\n",
    "    'phone': ['123-456-7891', '987-654-3211', '', '555-999-8888'],\n",
    "    'address': ['124 Main St', '457 Oak Ave', '790 Pine Rd', '322 Elm St']\n",
    "})\n",
    "\n",
    "print(\"SAMPLE DATASETS:\")\n",
    "print(\"\\nTable A:\")\n",
    "print(A.to_string(index=False))\n",
    "print(\"\\nTable B:\")\n",
    "print(B.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc4976",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Different Feature Creation Configurations\n",
    "\n",
    "The `create_features()` function can be customized in several ways:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935d61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FEATURE CREATION CONFIGURATIONS:\\n\")\n",
    "\n",
    "# 1. Default configuration (automatic feature generation)\n",
    "features_default = create_features(A, B, a_cols=['name', 'age'], b_cols=['name', 'age'])\n",
    "print(f\"DEFAULT FEATURES ({len(features_default)} features):\")\n",
    "for i, feature in enumerate(features_default):\n",
    "    print(f\"   {i+1}. {feature}\")\n",
    "print()\n",
    "\n",
    "# 2. Only numeric columns (for RelDiff features)\n",
    "features_numeric = create_features(A, B, a_cols=['age'], b_cols=['age'])\n",
    "print(f\"NUMERIC-ONLY FEATURES ({len(features_numeric)} features):\")\n",
    "for i, feature in enumerate(features_numeric):\n",
    "    print(f\"   {i+1}. {feature}\")\n",
    "print()\n",
    "\n",
    "# 3. Custom tokenizers and similarity functions\n",
    "from madmatcher_tools._internal.tokenizer.tokenizer import AlphaNumericTokenizer\n",
    "from madmatcher_tools._internal.feature.token_feature import JaccardFeature, CosineFeature\n",
    "\n",
    "custom_tokenizers = [AlphaNumericTokenizer()]\n",
    "custom_sim_functions = [JaccardFeature, CosineFeature]\n",
    "\n",
    "features_custom = create_features(\n",
    "    A, B, \n",
    "    a_cols=['name'], b_cols=['name'],\n",
    "    tokenizers=custom_tokenizers,\n",
    "    sim_functions=custom_sim_functions\n",
    ")\n",
    "print(f\"CUSTOM TOKENIZERS & SIM FUNCTIONS ({len(features_custom)} features):\")\n",
    "for i, feature in enumerate(features_custom):\n",
    "    print(f\"   {i+1}. {feature}\")\n",
    "print()\n",
    "\n",
    "# 4. High null threshold (filters out columns with many missing values)\n",
    "features_filtered = create_features(\n",
    "    A, B, \n",
    "    a_cols=['name', 'age', 'email'], b_cols=['name', 'age', 'email'],\n",
    "    null_threshold=0.3  # Only use columns with <30% null values\n",
    ")\n",
    "print(f\"NULL-FILTERED FEATURES ({len(features_filtered)} features):\")\n",
    "for i, feature in enumerate(features_filtered):\n",
    "    print(f\"   {i+1}. {feature}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bab20",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Featurization\n",
    "\n",
    "Featurization applies the generated features to candidate record pairs, producing feature vectors for machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8af09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different types of candidate pairs\n",
    "print(\"FEATURIZATION EXAMPLES:\\n\")\n",
    "\n",
    "# 1. Basic candidate pairs (one-to-one mapping)\n",
    "candidates_basic = pd.DataFrame({\n",
    "    'id1_list': [[1], [2], [3], [4]],  # Each record from A\n",
    "    'id2': [101, 102, 103, 104]        # Paired with record from B\n",
    "})\n",
    "\n",
    "# 2. One-to-many candidates (blocking results)\n",
    "candidates_blocked = pd.DataFrame({\n",
    "    'id1_list': [[1, 2], [3], [4]],    # Multiple A records can match one B record\n",
    "    'id2': [101, 103, 104]\n",
    "})\n",
    "\n",
    "# 3. Custom candidates with additional metadata\n",
    "candidates_custom = pd.DataFrame({\n",
    "    'id1_list': [[1], [2], [3]],\n",
    "    'id2': [101, 102, 103],\n",
    "    'block_id': ['name_block_1', 'name_block_2', 'name_block_1'],  # Additional info\n",
    "    'similarity_score': [0.8, 0.6, 0.9]  # Pre-computed scores\n",
    "})\n",
    "\n",
    "print(\"CANDIDATE PAIR EXAMPLES:\")\n",
    "print(\"\\n1. Basic pairs:\")\n",
    "print(candidates_basic)\n",
    "print(\"\\n2. Blocked pairs (one-to-many):\")  \n",
    "print(candidates_blocked)\n",
    "print(\"\\n3. Custom pairs with metadata:\")\n",
    "print(candidates_custom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply featurization with different configurations\n",
    "print(\"\\nFEATURIZATION RESULTS:\\n\")\n",
    "\n",
    "# Use the default features for comprehensive comparison\n",
    "features = features_default\n",
    "\n",
    "# 1. Basic featurization\n",
    "fvs_basic = featurize(features, A, B, candidates_basic)\n",
    "print(f\"BASIC FEATURIZATION:\")\n",
    "print(f\" Shape: {fvs_basic.shape}\")\n",
    "print(f\" Columns: {list(fvs_basic.columns)}\")\n",
    "print(f\" Feature vector length: {len(fvs_basic['features'].iloc[0])}\")\n",
    "print(f\" Sample feature vector: {fvs_basic['features'].iloc[0][:5]}... (showing first 5)\")\n",
    "print()\n",
    "\n",
    "# 2. Featurization with custom output column name\n",
    "fvs_custom_col = featurize(features, A, B, candidates_basic, output_col='similarity_features')\n",
    "print(f\"CUSTOM OUTPUT COLUMN:\")\n",
    "print(f\" Columns: {list(fvs_custom_col.columns)}\")\n",
    "print()\n",
    "\n",
    "# 3. Featurization with fill_na parameter\n",
    "fvs_filled = featurize(features, A, B, candidates_basic, fill_na=0.0)\n",
    "print(f\"WITH NaN FILLING:\")\n",
    "print(f\" NaN count in features: {sum(np.isnan(x).sum() for x in fvs_basic['features'])}\")\n",
    "print(f\" NaN count after filling: {sum(np.isnan(x).sum() for x in fvs_filled['features'])}\")\n",
    "print()\n",
    "\n",
    "# Display sample results\n",
    "print(\"SAMPLE FEATURIZATION OUTPUT:\")\n",
    "print(fvs_basic[['id2', 'id1', '_id']].head())\n",
    "print(\"\\nFeature vectors (first 3 features for first 3 pairs):\")\n",
    "for i in range(min(3, len(fvs_basic))):\n",
    "    print(f\" Pair {i+1}: {fvs_basic['features'].iloc[i][:3]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c33a4",
   "metadata": {},
   "source": [
    "## Down Sampling\n",
    "\n",
    "Down sampling reduces the size of your feature vector dataset while preserving the most promising candidate pairs based on a scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5958d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's work with our basic feature vectors and add scores\n",
    "fvs = fvs_basic.copy()\n",
    "\n",
    "# Add various types of scores for demonstration\n",
    "np.random.seed(42)  # For reproducible results\n",
    "fvs['score'] = np.random.beta(2, 5, len(fvs))  # Simulated similarity scores\n",
    "fvs['random_score'] = np.random.uniform(0, 1, len(fvs))\n",
    "\n",
    "print(\"DOWN SAMPLING EXAMPLES:\\n\")\n",
    "print(f\"Original dataset size: {len(fvs)} pairs\")\n",
    "print(\"Original scores:\", fvs['score'].round(3).tolist())\n",
    "print()\n",
    "\n",
    "# 1. Basic down sampling (50%)\n",
    "down_50 = down_sample(fvs, percent=0.5, search_id_column='id2')\n",
    "print(f\"50% DOWN SAMPLING:\")\n",
    "print(f\" Result size: {len(down_50)} pairs\")\n",
    "print(f\" Retained scores: {down_50['score'].round(3).tolist()}\")\n",
    "print()\n",
    "\n",
    "# 2. Aggressive down sampling (25%)  \n",
    "down_25 = down_sample(fvs, percent=0.25, search_id_column='id2')\n",
    "print(f\"25% DOWN SAMPLING:\")\n",
    "print(f\" Result size: {len(down_25)} pairs\")\n",
    "print(f\" Retained scores: {down_25['score'].round(3).tolist()}\")\n",
    "print()\n",
    "\n",
    "# 3. Custom score column\n",
    "down_custom = down_sample(fvs, percent=0.5, search_id_column='id2', score_column='random_score')\n",
    "print(f\"CUSTOM SCORE COLUMN:\")\n",
    "print(f\" Result size: {len(down_custom)} pairs\")\n",
    "print(f\" Retained random_scores: {down_custom['random_score'].round(3).tolist()}\")\n",
    "print()\n",
    "\n",
    "# 4. Custom bucket size for large datasets\n",
    "down_buckets = down_sample(fvs, percent=0.75, search_id_column='id2', bucket_size=2)\n",
    "print(f\"CUSTOM BUCKET SIZE:\")\n",
    "print(f\" Result size: {len(down_buckets)} pairs\")\n",
    "print(f\" Bucket size parameter: 2 (for demonstration)\")\n",
    "print()\n",
    "\n",
    "print(\"Note: Down sampling preserves the highest-scoring pairs within each hash bucket.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9a2d5e",
   "metadata": {},
   "source": [
    "## Seed Creation\n",
    "\n",
    "Seeds are initial labeled examples used to train machine learning models. MadMatcher supports various labeling strategies for creating these seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc5657",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SEED CREATION EXAMPLES:\\n\")\n",
    "\n",
    "# Create different types of labelers for demonstration\n",
    "\n",
    "# 1. Gold standard labeler (ground truth)\n",
    "gold_labels = pd.DataFrame({\n",
    "    'id1': [1, 3, 4],        # Records from table A\n",
    "    'id2': [101, 103, 104]   # Matching records from table B  \n",
    "})\n",
    "print(\"Ground truth matches:\")\n",
    "print(gold_labels)\n",
    "print()\n",
    "\n",
    "gold_labeler = {'name': 'gold', 'gold': gold_labels}\n",
    "\n",
    "# 2. Create a custom always-positive labeler\n",
    "class AlwaysPositiveLabeler(Labeler):\n",
    "    def __call__(self, id1, id2):\n",
    "        return 1.0  # Always return positive match\n",
    "\n",
    "# 3. Create a custom rule-based labeler  \n",
    "class RuleBasedLabeler(Labeler):\n",
    "    def __call__(self, id1, id2):\n",
    "        # Simple rule: match if id2 - id1 == 100\n",
    "        return 1.0 if (id2 - id1) == 100 else 0.0\n",
    "\n",
    "print(\"DIFFERENT LABELING STRATEGIES:\\n\")\n",
    "\n",
    "# Test with gold labeler\n",
    "seeds_gold = create_seeds(fvs, nseeds=3, labeler=gold_labeler)\n",
    "print(\"GOLD STANDARD LABELER:\")\n",
    "print(f\" Seeds created: {len(seeds_gold)}\")\n",
    "print(f\" Positive labels: {sum(seeds_gold['label'] == 1.0)}\")\n",
    "print(f\" Negative labels: {sum(seeds_gold['label'] == 0.0)}\")\n",
    "print(\"  Sample seeds:\")\n",
    "print(seeds_gold[['id1', 'id2', 'score', 'label']].to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Test with rule-based labeler\n",
    "rule_labeler = RuleBasedLabeler()\n",
    "seeds_rule = create_seeds(fvs, nseeds=3, labeler=rule_labeler)\n",
    "print(\"RULE-BASED LABELER:\")\n",
    "print(f\" Seeds created: {len(seeds_rule)}\")\n",
    "print(f\" Positive labels: {sum(seeds_rule['label'] == 1.0)}\")\n",
    "print(f\" Negative labels: {sum(seeds_rule['label'] == 0.0)}\")\n",
    "print(\"  Sample seeds:\")\n",
    "print(seeds_rule[['id1', 'id2', 'score', 'label']].to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Test with always-positive labeler\n",
    "positive_labeler = AlwaysPositiveLabeler()\n",
    "seeds_positive = create_seeds(fvs, nseeds=2, labeler=positive_labeler)\n",
    "print(\"ALWAYS-POSITIVE LABELER:\")\n",
    "print(f\" Seeds created: {len(seeds_positive)}\")\n",
    "print(f\" All labels: {seeds_positive['label'].tolist()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf3c22",
   "metadata": {},
   "source": [
    "## Training a Matcher\n",
    "\n",
    "MadMatcher supports various machine learning models for training matchers, including scikit-learn models and custom implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee85b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRAINING DIFFERENT TYPES OF MATCHERS:\\n\")\n",
    "\n",
    "# Use the gold standard seeds for training\n",
    "seeds = seeds_gold\n",
    "labeled_data = seeds.copy()\n",
    "\n",
    "print(f\"Training data: {len(labeled_data)} labeled examples\")\n",
    "print(f\"Feature vector dimension: {len(labeled_data['features'].iloc[0])}\")\n",
    "print()\n",
    "\n",
    "# 1. Logistic Regression\n",
    "model_lr = train_matcher(\n",
    "    {'model_type': 'sklearn', 'model': LogisticRegression, 'nan_fill': 0, 'model_args': {'random_state': 42}}, \n",
    "    labeled_data\n",
    ")\n",
    "print(\"LOGISTIC REGRESSION MODEL:\")\n",
    "print(f\" Model type: {type(model_lr.trained_model).__name__}\")\n",
    "print(f\" Parameters: {model_lr.params_dict()}\")\n",
    "print()\n",
    "\n",
    "# 2. Random Forest\n",
    "model_rf = train_matcher(\n",
    "    {'model_type': 'sklearn', 'model': RandomForestClassifier, 'nan_fill': 0,\n",
    "     'model_args': {'n_estimators': 10, 'random_state': 42}}, \n",
    "    labeled_data\n",
    ")\n",
    "print(\"RANDOM FOREST MODEL:\")\n",
    "print(f\" Model type: {type(model_rf.trained_model).__name__}\")\n",
    "print(f\" Parameters: {model_rf.params_dict()}\")\n",
    "print()\n",
    "\n",
    "# 3. Custom MLModel implementation\n",
    "class SimpleThresholdModel(MLModel):\n",
    "    def __init__(self, threshold=0.5):\n",
    "        self.threshold = threshold\n",
    "        self._trained = False\n",
    "        self._trained_model = None\n",
    "        \n",
    "    @property\n",
    "    def nan_fill(self): return 0.0\n",
    "    @property  \n",
    "    def use_vectors(self): return False\n",
    "    @property\n",
    "    def use_floats(self): return True\n",
    "\n",
    "    def trained_model(self):\n",
    "        return self._trained_model\n",
    "        \n",
    "    def train(self, df, vector_col, label_column, return_estimator=False):\n",
    "        self._trained = True\n",
    "        self._trained_model = self\n",
    "        return self\n",
    "        \n",
    "    def predict(self, df, vector_col, output_col):\n",
    "        # Simple rule: predict 1 if first feature > threshold\n",
    "        df = df.copy()\n",
    "        df[output_col] = df[vector_col].apply(lambda x: 1.0 if len(x) > 0 and x[0] > self.threshold else 0.0)\n",
    "        return df\n",
    "        \n",
    "    def prediction_conf(self, df, vector_col, label_column):\n",
    "        df = df.copy()\n",
    "        df['conf'] = 0.8  # Fixed confidence\n",
    "        return df\n",
    "        \n",
    "    def entropy(self, df, vector_col, output_col):\n",
    "        df = df.copy()\n",
    "        df[output_col] = 0.5  # Fixed entropy\n",
    "        return df\n",
    "        \n",
    "    def params_dict(self):\n",
    "        return {'threshold': self.threshold, 'trained': self._trained}\n",
    "\n",
    "custom_model = SimpleThresholdModel(threshold=0.1)\n",
    "model_custom = train_matcher(custom_model, labeled_data)\n",
    "print(\"CUSTOM THRESHOLD MODEL:\")\n",
    "print(f\" Model type: {type(model_custom).__name__}\")\n",
    "print(f\" Parameters: {model_custom.params_dict()}\")\n",
    "print()\n",
    "\n",
    "print(\"All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0f91a",
   "metadata": {},
   "source": [
    "## Applying a Matcher\n",
    "\n",
    "Once trained, matchers can be applied to new data to generate predictions and confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d5cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"APPLYING TRAINED MATCHERS:\\n\")\n",
    "\n",
    "# Apply different trained models to the same feature vectors\n",
    "test_fvs = fvs.copy()\n",
    "\n",
    "# 1. Apply Logistic Regression model\n",
    "result_lr = apply_matcher(model_lr, test_fvs, feature_col='features', output_col='lr_prediction')\n",
    "print(\"LOGISTIC REGRESSION PREDICTIONS:\")\n",
    "print(result_lr[['id1', 'id2', 'score', 'lr_prediction']].head())\n",
    "print(f\" Positive predictions: {sum(result_lr['lr_prediction'] == 1.0)}/{len(result_lr)}\")\n",
    "print()\n",
    "\n",
    "# 2. Apply Random Forest model\n",
    "result_rf = apply_matcher(model_rf, test_fvs, feature_col='features', output_col='rf_prediction')\n",
    "print(\"RANDOM FOREST PREDICTIONS:\")\n",
    "print(result_rf[['id1', 'id2', 'score', 'rf_prediction']].head())\n",
    "print(f\" Positive predictions: {sum(result_rf['rf_prediction'] == 1.0)}/{len(result_rf)}\")\n",
    "print()\n",
    "\n",
    "# 3. Apply Custom Threshold model\n",
    "result_custom = apply_matcher(model_custom, test_fvs, feature_col='features', output_col='custom_prediction')\n",
    "print(\"CUSTOM THRESHOLD PREDICTIONS:\")\n",
    "print(result_custom[['id1', 'id2', 'score', 'custom_prediction']].head())\n",
    "print(f\" Positive predictions: {sum(result_custom['custom_prediction'] == 1.0)}/{len(result_custom)}\")\n",
    "print()\n",
    "\n",
    "# 4. Compare all predictions\n",
    "comparison = pd.DataFrame({\n",
    "    'id1': result_lr['id1'],\n",
    "    'id2': result_lr['id2'],\n",
    "    'original_score': result_lr['score'].round(3),\n",
    "    'lr_pred': result_lr['lr_prediction'],\n",
    "    'rf_pred': result_rf['rf_prediction'],\n",
    "    'custom_pred': result_custom['custom_prediction']\n",
    "})\n",
    "\n",
    "print(\"PREDICTION COMPARISON:\")\n",
    "print(comparison.to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Calculate agreement between models\n",
    "lr_rf_agreement = sum(result_lr['lr_prediction'] == result_rf['rf_prediction']) / len(result_lr)\n",
    "print(f\"Model Agreement:\")\n",
    "print(f\" LR vs RF: {lr_rf_agreement:.2%}\")\n",
    "print(f\" LR vs Custom: {sum(result_lr['lr_prediction'] == result_custom['custom_prediction']) / len(result_lr):.2%}\")\n",
    "print(f\" RF vs Custom: {sum(result_rf['rf_prediction'] == result_custom['custom_prediction']) / len(result_rf):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6defadd4",
   "metadata": {},
   "source": [
    "## Active Learning Labeling\n",
    "\n",
    "**Note**: The `label_data` function has a bug in the current version (line 157 in tools.py). This section demonstrates the intended usage, but the function may need to be fixed first.\n",
    "\n",
    "Active learning helps efficiently label data by selecting the most informative examples for human review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ACTIVE LEARNING LABELING (INTENDED USAGE):\\n\")\n",
    "\n",
    "# Due to the bug in label_data function, we'll demonstrate the intended usage\n",
    "# and provide a manual implementation\n",
    "\n",
    "print(\"âŒ Current issue: label_data function has a bug in create_seeds when handling Spark DataFrames\")\n",
    "print(\"ðŸ”§ Here's how it should work:\\n\")\n",
    "\n",
    "print(\"INTENDED USAGE:\")\n",
    "print(\"\"\"\n",
    "# Batch mode active learning\n",
    "labels_batch = label_data(\n",
    "    model_spec={'model_type': 'sklearn', 'model': LogisticRegression, 'model_args': {}},\n",
    "    mode='batch',\n",
    "    labeler_spec=gold_labeler,\n",
    "    fvs=fvs\n",
    ")\n",
    "\n",
    "# Continuous mode active learning  \n",
    "labels_continuous = label_data(\n",
    "    model_spec={'model_type': 'sklearn', 'model': LogisticRegression, 'model_args': {}},\n",
    "    mode='continuous',\n",
    "    labeler_spec=gold_labeler,\n",
    "    fvs=fvs,\n",
    "    seeds=seeds_gold  # Optional pre-existing seeds\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nMANUAL ACTIVE LEARNING SIMULATION:\\n\")\n",
    "\n",
    "# Simulate active learning workflow manually\n",
    "def simulate_active_learning(fvs, model, labeler, n_iterations=2):\n",
    "    \"\"\"Simulate the active learning process\"\"\"\n",
    "    current_labeled = seeds_gold.copy()\n",
    "    \n",
    "    for iteration in range(n_iterations):\n",
    "        print(f\"Iteration {iteration + 1}:\")\n",
    "        \n",
    "        # Train model on current labeled data\n",
    "        model = train_matcher(\n",
    "            {'model_type': 'sklearn', 'model': LogisticRegression, 'nan_fill': 0.0, 'model_args': {'random_state': 42}},\n",
    "            current_labeled\n",
    "        )\n",
    "        \n",
    "        # Apply model to get predictions and uncertainty (entropy would be better)\n",
    "        predictions = apply_matcher(model, fvs, 'features', 'prediction')\n",
    "        \n",
    "        # Simple uncertainty: pick examples closest to decision boundary (0.5)\n",
    "        predictions['uncertainty'] = predictions['prediction'].apply(lambda x: 1 - abs(x - 0.5) * 2)\n",
    "        \n",
    "        # Select most uncertain unlabeled example\n",
    "        unlabeled = predictions[~predictions.index.isin(current_labeled.index)]\n",
    "        if len(unlabeled) == 0:\n",
    "            break\n",
    "            \n",
    "        most_uncertain = unlabeled.loc[unlabeled['uncertainty'].idxmax()]\n",
    "        \n",
    "        # Get label from labeler\n",
    "        label = labeler(most_uncertain['id1'], most_uncertain['id2'])\n",
    "        \n",
    "        # Add to labeled set - only copy the necessary columns to avoid confusion\n",
    "        new_labeled = pd.DataFrame({\n",
    "            'id1': [most_uncertain['id1']],\n",
    "            'id2': [most_uncertain['id2']],\n",
    "            'features': [most_uncertain['features']],\n",
    "            'score': [most_uncertain['score']],\n",
    "            'label': [float(label)]  # Ensure label is float\n",
    "        })\n",
    "        current_labeled = pd.concat([current_labeled, new_labeled], ignore_index=True)\n",
    "        \n",
    "        print(f\" Selected pair: ({most_uncertain['id1']}, {most_uncertain['id2']})\")\n",
    "        print(f\" Uncertainty: {most_uncertain['uncertainty']:.3f}\")\n",
    "        print(f\" Label: {label}\")\n",
    "        print(f\" Total labeled: {len(current_labeled)}\")\n",
    "        print()\n",
    "    \n",
    "    return current_labeled\n",
    "\n",
    "# Run simulation\n",
    "final_labeled = simulate_active_learning(fvs, model_lr, rule_labeler)\n",
    "print(\"FINAL LABELED DATASET:\")\n",
    "print(final_labeled[['id1', 'id2', 'score', 'label']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee45ec0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Custom Abstract Classes\n",
    "\n",
    "MadMatcher's power comes from its extensibility. You can implement custom tokenizers, features, ML models, and labelers by extending the abstract base classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CUSTOM IMPLEMENTATION EXAMPLES:\\n\")\n",
    "\n",
    "# 1. Custom Tokenizer\n",
    "class ReverseWordTokenizer(Tokenizer):\n",
    "    \"\"\"Tokenizer that reverses each word before returning tokens\"\"\"\n",
    "    NAME = 'reverse_word_tokens'\n",
    "    \n",
    "    def tokenize(self, s):\n",
    "        if not isinstance(s, str):\n",
    "            return None\n",
    "        words = s.lower().split()\n",
    "        return [word[::-1] for word in words]  # Reverse each word\n",
    "\n",
    "# Test custom tokenizer\n",
    "reverse_tokenizer = ReverseWordTokenizer()\n",
    "print(\"CUSTOM TOKENIZER (ReverseWordTokenizer):\")\n",
    "test_string = \"Alice Smith\"\n",
    "print(f\" Input: '{test_string}'\")\n",
    "print(f\" Tokens: {reverse_tokenizer.tokenize(test_string)}\")\n",
    "print(f\" Name: {reverse_tokenizer.NAME}\")\n",
    "print()\n",
    "\n",
    "# 2. Custom Feature\n",
    "class WordCountDifferenceFeature(Feature):\n",
    "    \"\"\"Feature that computes absolute difference in word count\"\"\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'word_count_diff({self.a_attr}, {self.b_attr})'\n",
    "    \n",
    "    def __call__(self, rec, recs):\n",
    "        b_value = rec[self.b_attr]\n",
    "        a_values = recs[self.a_attr]\n",
    "        \n",
    "        if not isinstance(b_value, str):\n",
    "            return pd.Series(np.nan, index=a_values.index)\n",
    "        \n",
    "        b_word_count = len(b_value.split()) if b_value else 0\n",
    "        \n",
    "        def word_count_diff(a_value):\n",
    "            if not isinstance(a_value, str):\n",
    "                return np.nan\n",
    "            a_word_count = len(a_value.split()) if a_value else 0\n",
    "            return abs(a_word_count - b_word_count)\n",
    "        \n",
    "        return a_values.apply(word_count_diff).astype(np.float64)\n",
    "    \n",
    "    def _preprocess(self, data, input_col):\n",
    "        return data  # No preprocessing needed\n",
    "    \n",
    "    def _preprocess_output_column(self, attr):\n",
    "        return None  # No preprocessing output\n",
    "\n",
    "# Test custom feature\n",
    "custom_feature = WordCountDifferenceFeature('name', 'name')\n",
    "print(\"CUSTOM FEATURE (WordCountDifferenceFeature):\")\n",
    "print(f\" Feature string: {custom_feature}\")\n",
    "\n",
    "# Create test data for feature\n",
    "test_rec = {'name': 'Alice Smith'}\n",
    "test_recs = pd.DataFrame({'name': ['Bob Jones', 'Jean-Pierre O\\'Connor', 'X']})\n",
    "feature_result = custom_feature(test_rec, test_recs)\n",
    "print(f\" Input B: '{test_rec['name']}' (2 words)\")\n",
    "print(f\" Input A values: {test_recs['name'].tolist()}\")\n",
    "print(f\" Word count differences: {feature_result.tolist()}\")\n",
    "print()\n",
    "\n",
    "# 3. Custom Labeler with complex logic\n",
    "class SmartSimilarityLabeler(CustomLabeler):\n",
    "    \"\"\"Labeler that uses multiple criteria for matching\"\"\"\n",
    "    \n",
    "    def label_pair(self, row1, row2):\n",
    "        # Get name similarity (simple word overlap)\n",
    "        name1_words = set(row1['name'].lower().split())\n",
    "        name2_words = set(row2['name'].lower().split())\n",
    "        name_overlap = len(name1_words & name2_words) / max(len(name1_words | name2_words), 1)\n",
    "        \n",
    "        # Get age similarity \n",
    "        age1, age2 = row1.get('age'), row2.get('age')\n",
    "        age_diff = abs(age1 - age2) if (age1 is not None and age2 is not None) else float('inf')\n",
    "        \n",
    "        # Labeling logic\n",
    "        if name_overlap >= 0.5 and age_diff <= 5:\n",
    "            return 1.0  # Strong match\n",
    "        elif name_overlap >= 0.3 or age_diff <= 2:\n",
    "            return 0.5  # Uncertain (could be treated as unsure)\n",
    "        else:\n",
    "            return 0.0  # No match\n",
    "\n",
    "smart_labeler = SmartSimilarityLabeler(A, B)\n",
    "print(\"CUSTOM LABELER (SmartSimilarityLabeler):\")\n",
    "print(\" Logic: High name overlap + small age difference = match\")\n",
    "\n",
    "# Test the smart labeler\n",
    "test_pairs = [(1, 101), (2, 102), (3, 103), (4, 104)]\n",
    "for id1, id2 in test_pairs:\n",
    "    label = smart_labeler(id1, id2)\n",
    "    row1 = A[A['_id'] == id1].iloc[0]\n",
    "    row2 = B[B['_id'] == id2].iloc[0]\n",
    "    print(f\" Pair ({id1},{id2}): '{row1['name']}' vs '{row2['name']}' â†’ {label}\")\n",
    "print()\n",
    "\n",
    "# 4. Demonstrate custom implementations in pipeline\n",
    "print(\"USING CUSTOM COMPONENTS IN PIPELINE:\")\n",
    "\n",
    "# Create features with custom tokenizer\n",
    "custom_features = create_features(\n",
    "    A, B, \n",
    "    a_cols=['name'], b_cols=['name'],\n",
    "    tokenizers=[reverse_tokenizer],\n",
    "    sim_functions=get_base_sim_functions()[:2]  # Use first 2 similarity functions\n",
    ")\n",
    "\n",
    "# Add our custom feature\n",
    "custom_features.append(custom_feature)\n",
    "\n",
    "print(f\" Created {len(custom_features)} features (including custom)\")\n",
    "for i, feature in enumerate(custom_features):\n",
    "    print(f\"   {i+1}. {feature}\")\n",
    "print()\n",
    "\n",
    "# Test featurization with custom features\n",
    "small_candidates = pd.DataFrame({'id1_list': [[1], [2]], 'id2': [101, 102]})\n",
    "custom_fvs = featurize(custom_features, A, B, small_candidates)\n",
    "\n",
    "print(f\" Custom featurization result shape: {custom_fvs.shape}\")\n",
    "print(f\" Feature vector length: {len(custom_fvs['features'].iloc[0])}\")\n",
    "print(\"  Custom components integrated successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4165e0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Advanced Examples\n",
    "\n",
    "This section demonstrates more complex usage patterns and best practices for real-world entity matching scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53edc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ADVANCED USAGE PATTERNS:\\n\")\n",
    "\n",
    "# 1. Multi-column feature engineering\n",
    "print(\"MULTI-COLUMN FEATURE ENGINEERING:\")\n",
    "\n",
    "# Create features for all available columns\n",
    "all_features = create_features(\n",
    "    A, B,\n",
    "    a_cols=['name', 'age', 'email', 'phone', 'address'],\n",
    "    b_cols=['name', 'age', 'email', 'phone', 'address'],\n",
    "    null_threshold=0.7  # Allow columns with up to 70% missing values\n",
    ")\n",
    "\n",
    "print(f\" Generated {len(all_features)} features across all columns:\")\n",
    "feature_types = {}\n",
    "for feature in all_features:\n",
    "    feature_type = type(feature).__name__\n",
    "    feature_types[feature_type] = feature_types.get(feature_type, 0) + 1\n",
    "\n",
    "for ftype, count in feature_types.items():\n",
    "    print(f\"   {ftype}: {count}\")\n",
    "print()\n",
    "\n",
    "# 2. Feature selection and evaluation\n",
    "print(\"FEATURE EVALUATION:\")\n",
    "\n",
    "# Apply all features to get comprehensive feature vectors\n",
    "comprehensive_fvs = featurize(all_features, A, B, candidates_basic)\n",
    "comprehensive_fvs['simple_score'] = comprehensive_fvs['features'] \\\n",
    "    .apply(lambda fv: np.nansum(fv))\n",
    "print(f\" Full feature vector dimension: {len(comprehensive_fvs['features'].iloc[0])}\")\n",
    "\n",
    "# Calculate feature statistics\n",
    "feature_stats = []\n",
    "for i in range(len(comprehensive_fvs['features'].iloc[0])):\n",
    "    feature_values = [fv[i] for fv in comprehensive_fvs['features']]\n",
    "    arr = np.array(feature_values, dtype=float)\n",
    "    non_nan = arr[~np.isnan(arr)]\n",
    "    unique_values = len(set(non_nan))\n",
    "    stats = {\n",
    "        'feature_idx': i,\n",
    "        'mean': np.nanmean(feature_values),\n",
    "        'std': np.nanstd(feature_values),\n",
    "        'nan_count': sum(np.isnan(feature_values)),\n",
    "        'unique_values': unique_values\n",
    "    }\n",
    "    feature_stats.append(stats)\n",
    "\n",
    "# Display top features by variance (good features should have variability)\n",
    "feature_stats_df = pd.DataFrame(feature_stats)\n",
    "feature_stats_df['variance'] = feature_stats_df['std'] ** 2\n",
    "top_features = feature_stats_df.nlargest(5, 'variance')\n",
    "\n",
    "print(\" Top 5 features by variance:\")\n",
    "print(top_features[['feature_idx', 'mean', 'std', 'variance']].round(4).to_string(index=False))\n",
    "print()\n",
    "\n",
    "# 3. Model comparison and ensemble\n",
    "print(\"MODEL ENSEMBLE:\")\n",
    "\n",
    "# Train multiple models on the comprehensive features\n",
    "models = {}\n",
    "model_configs = [\n",
    "    ('LR', {'model_type': 'sklearn', 'model': LogisticRegression, 'nan_fill': 0.0, 'model_args': {'random_state': 42}}),\n",
    "    ('RF', {'model_type': 'sklearn', 'model': RandomForestClassifier, 'nan_fill': 0.0, 'model_args': {'n_estimators': 10, 'random_state': 42}}),\n",
    "]\n",
    "\n",
    "# Use comprehensive seeds for training\n",
    "comprehensive_seeds = create_seeds(comprehensive_fvs, nseeds=4, labeler=gold_labeler, score_column='simple_score')\n",
    "print(comprehensive_seeds)\n",
    "for name, config in model_configs:\n",
    "    models[name] = train_matcher(config, comprehensive_seeds)\n",
    "    print(f\" Trained {name} model\")\n",
    "\n",
    "# Apply all models and create ensemble\n",
    "ensemble_results = comprehensive_fvs[['id1', 'id2']].copy()\n",
    "\n",
    "for name, model in models.items():\n",
    "    result = apply_matcher(model, comprehensive_fvs, 'features', f'{name}_pred')\n",
    "    ensemble_results[f'{name}_pred'] = result[f'{name}_pred']\n",
    "\n",
    "# Simple ensemble: average predictions\n",
    "ensemble_results['ensemble_pred'] = ensemble_results[['LR_pred', 'RF_pred']].mean(axis=1)\n",
    "ensemble_results['ensemble_pred_binary'] = (ensemble_results['ensemble_pred'] > 0.5).astype(float)\n",
    "\n",
    "print(\" Ensemble results:\")\n",
    "print(ensemble_results.round(3).to_string(index=False))\n",
    "print()\n",
    "\n",
    "# 4. Performance evaluation simulation\n",
    "print(\"PERFORMANCE EVALUATION:\")\n",
    "\n",
    "# Simulate evaluation against ground truth\n",
    "ground_truth = {(1, 101): 1, (2, 102): 0, (3, 103): 1, (4, 104): 1}\n",
    "\n",
    "def evaluate_predictions(predictions, truth_dict):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for _, row in predictions.iterrows():\n",
    "        pair = (row['id1'], row['id2'])\n",
    "        if pair in truth_dict:\n",
    "            pred = row['ensemble_pred_binary']\n",
    "            true_label = truth_dict[pair]\n",
    "            if pred == true_label:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "accuracy = evaluate_predictions(ensemble_results, ground_truth)\n",
    "print(f\" Ensemble accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Calculate precision and recall\n",
    "true_positives = sum(1 for _, row in ensemble_results.iterrows() \n",
    "                    if (row['id1'], row['id2']) in ground_truth \n",
    "                    and ground_truth[(row['id1'], row['id2'])] == 1 \n",
    "                    and row['ensemble_pred_binary'] == 1)\n",
    "\n",
    "predicted_positives = sum(ensemble_results['ensemble_pred_binary'])\n",
    "actual_positives = sum(ground_truth.values())\n",
    "\n",
    "precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "\n",
    "print(f\" Precision: {precision:.2%}\")\n",
    "print(f\" Recall: {recall:.2%}\")\n",
    "print()\n",
    "\n",
    "print(\"Advanced examples completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee7f0a0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This comprehensive notebook has demonstrated all the key functionality of MadMatcher:\n",
    "\n",
    "### Core Functions Covered\n",
    "**Tokenizers & Similarity Functions**: Understanding the building blocks  \n",
    "**Feature Creation**: Automatic and custom feature generation  \n",
    "**Featurization**: Converting candidate pairs to feature vectors  \n",
    "**Down Sampling**: Efficient dataset reduction  \n",
    "**Seed Creation**: Generating initial training labels  \n",
    "**Model Training**: Multiple ML approaches  \n",
    "**Model Application**: Making predictions  \n",
    "**Active Learning**: Efficient labeling strategies  \n",
    "\n",
    "### Abstract Classes Extended\n",
    "**Custom Tokenizer**: `ReverseWordTokenizer`  \n",
    "**Custom Feature**: `WordCountDifferenceFeature`  \n",
    "**Custom MLModel**: `SimpleThresholdModel`  \n",
    "**Custom Labeler**: `SmartSimilarityLabeler`  \n",
    "\n",
    "### Advanced Patterns\n",
    "**Multi-column Feature Engineering**  \n",
    "**Feature Evaluation & Selection**  \n",
    "**Model Ensembles**  \n",
    "**Performance Evaluation**  \n",
    "\n",
    "\n",
    "For more information, visit the [MadMatcher Website](https://madmatcher.ai) or explore the source code in the `madmatcher_tools` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd99273-97d5-4de7-a409-b2343b7fc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up Spark session\n",
    "spark.stop()\n",
    "print(\"Spark session stopped. Notebook complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23845716-de62-40df-87d1-a9b1c25a6b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkly",
   "language": "python",
   "name": "sparkly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
